{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0054b36f-4f5f-40cc-b859-a99cb4edea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split,train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,mean_squared_error, mean_absolute_error, r2_score,confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "286643c7-3df0-44e6-9ade-6f8df3686552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'sagemaker-studio-905418013525-nvxe84zgs6'\n",
    "file_path = 'Labrado/alllabs1000adm/alllabs1000adm0518.csv'\n",
    "obj = s3.get_object(Bucket=bucket_name, Key=file_path)\n",
    "rawdata = pd.read_csv(obj['Body'])",
    "rawdata=rawdata.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6e8e952-15c4-470b-bab9-d6f64cc6b487",
   "metadata": {},
   "outputs": [],
   "source": [
    "Labitemlist = rawdata['itemid'].value_counts().sort_values(ascending=False)\n",
    "Labitemlist = Labitemlist.reset_index()\n",
    "Labitemlist.columns = ['itemid', 'count']\n",
    "len(Labitemlist)\n",
    "Labitem_dict = dict(zip(Labitemlist['itemid'], Labitemlist.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1fdf3838-a562-4033-8e2e-c97ef6f3c1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50971</td>\n",
       "      <td>2078644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50983</td>\n",
       "      <td>2058719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50902</td>\n",
       "      <td>2042431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51221</td>\n",
       "      <td>2041697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50912</td>\n",
       "      <td>1995732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50882</td>\n",
       "      <td>1987133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50868</td>\n",
       "      <td>1981798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>51006</td>\n",
       "      <td>1981280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50931</td>\n",
       "      <td>1932304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>51265</td>\n",
       "      <td>1928290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemid    count\n",
       "0   50971  2078644\n",
       "1   50983  2058719\n",
       "2   50902  2042431\n",
       "3   51221  2041697\n",
       "4   50912  1995732\n",
       "5   50882  1987133\n",
       "6   50868  1981798\n",
       "7   51006  1981280\n",
       "8   50931  1932304\n",
       "9   51265  1928290"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Labitemlist.iloc[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "211d1335-601d-4701-9de2-3a5aafc64e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_adm_year_day = rawdata[['hadm_id','chartyear', 'charttime_diff_days']].drop_duplicates().reset_index(drop=True)\n",
    "unique_adm_year_day['rowinx'] = unique_adm_year_day.index\n",
    "rawdata_index = pd.merge(rawdata, unique_adm_year_day, on=['hadm_id','chartyear', 'charttime_diff_days'], how='left')\n",
    "rawdata_index['colinx'] = [Labitem_dict[itemid] for itemid in rawdata_index['itemid'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb1de330-a5b5-4dd7-b238-a7516d06bdab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64914520, 10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c47a937-f0c5-4a50-b16d-533d2b649b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1966621, 4)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_adm_year_day.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1c5a4705-7c0d-4fea-9721-98b06a80f601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split year is 2178\n"
     ]
    }
   ],
   "source": [
    "unique_hadm_by_year = unique_adm_year_day.groupby('chartyear')['hadm_id'].nunique()\n",
    "cumulative_sum = unique_hadm_by_year.cumsum()\n",
    "total_sum = cumulative_sum.iloc[-1]\n",
    "split_index = cumulative_sum[cumulative_sum >= 0.8 * total_sum].index[0]\n",
    "print(\"split year is\",split_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b561487-cf70-44a9-b231-0623c8a5fa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "Row_Train = unique_adm_year_day['chartyear']<=split_index\n",
    "Train_inx = Row_Train[Row_Train].index\n",
    "Row_Test = unique_adm_year_day['chartyear']>split_index\n",
    "Test_inx = Row_Test[Row_Test].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0804c014-d3e4-40c0-ab7e-ac8a9fff8d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "npval = np.full((unique_adm_year_day.shape[0],len(Labitemlist)), np.nan)\n",
    "nptime = np.full((unique_adm_year_day.shape[0],len(Labitemlist)), np.nan)\n",
    "# Assign the value to npdata at the identified rows and columns\n",
    "npval[rawdata_index['rowinx'], rawdata_index['colinx']] = rawdata_index['valuenum']\n",
    "nptime[rawdata_index['rowinx'], rawdata_index['colinx']] = 24-rawdata_index['charthour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "776933ac-b546-47a6-a7db-5071bc4b20d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadm_id_indices = unique_adm_year_day.groupby('hadm_id').apply(lambda group: {'start_index': group.index.min(), 'end_index': group.index.max()+1}).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ec94a43-a84d-4a30-9ca3-681e7cc22f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "npval_last = np.full((unique_adm_year_day.shape[0],len(Labitemlist)), np.nan)\n",
    "nptime_last = np.full((unique_adm_year_day.shape[0],len(Labitemlist)), np.nan)\n",
    "for hadm_id, val in list(hadm_id_indices.items()):\n",
    "    rownum = val['end_index']-val['start_index']-1\n",
    "    if rownum >0:\n",
    "        npval_last[val['start_index']+1,:] = npval[val['start_index'],:]\n",
    "        nptime_last[val['start_index']+1,:] =  nptime[val['start_index'],:]+24\n",
    "        for i in range(val['start_index']+2, val['end_index']):\n",
    "            mask_nan = np.isnan(npval[i-1,:])\n",
    "            npval_last[i,:] = np.where(mask_nan, npval_last[i-1,:], npval[i-1,:])\n",
    "            nptime_last[i,:] = np.where(mask_nan, nptime_last[i-1,:]+24, nptime[i-1,:]+24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be61a4f1-8d51-4f1d-bbcc-617e34ee34c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>chartyear</th>\n",
       "      <th>charttime_diff_days</th>\n",
       "      <th>rowinx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>20006369</td>\n",
       "      <td>2111</td>\n",
       "      <td>2</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>20006377</td>\n",
       "      <td>2157</td>\n",
       "      <td>0</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>20006377</td>\n",
       "      <td>2157</td>\n",
       "      <td>1</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>20006377</td>\n",
       "      <td>2157</td>\n",
       "      <td>2</td>\n",
       "      <td>1006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>20006377</td>\n",
       "      <td>2157</td>\n",
       "      <td>3</td>\n",
       "      <td>1007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>20006377</td>\n",
       "      <td>2157</td>\n",
       "      <td>4</td>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>20006377</td>\n",
       "      <td>2157</td>\n",
       "      <td>5</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>20006377</td>\n",
       "      <td>2157</td>\n",
       "      <td>6</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hadm_id  chartyear  charttime_diff_days  rowinx\n",
       "1003  20006369       2111                    2    1003\n",
       "1004  20006377       2157                    0    1004\n",
       "1005  20006377       2157                    1    1005\n",
       "1006  20006377       2157                    2    1006\n",
       "1007  20006377       2157                    3    1007\n",
       "1008  20006377       2157                    4    1008\n",
       "1009  20006377       2157                    5    1009\n",
       "1010  20006377       2157                    6    1010"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_adm_year_day.iloc[1003:1011,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c7a3375-f5cf-420b-84b7-e5d1e429fd93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.5, 137. , 103. , ...,   nan,   nan,   nan],\n",
       "       [  3.7, 136. , 100. , ...,   nan,   nan,   nan],\n",
       "       [  3.9, 138. , 102. , ...,   nan,   nan,   nan],\n",
       "       ...,\n",
       "       [  nan,   nan,   nan, ...,   nan,   nan,   nan],\n",
       "       [  nan,   nan,   nan, ...,   nan,   nan,   nan],\n",
       "       [  nan,   nan,   nan, ...,   nan,   nan,   nan]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67106fff-2940-4201-bb5b-c8351b98e7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  nan,   nan,   nan, ...,   nan,   nan,   nan],\n",
       "       [  4. , 141. , 103. , ...,   nan,   nan,   nan],\n",
       "       [  4.2, 140. , 103. , ...,   nan,   nan,   nan],\n",
       "       [  4.6, 137. , 103. , ...,   nan,   nan,   nan],\n",
       "       [  5.4, 136. ,  99. , ...,   nan,   nan,   nan],\n",
       "       [  4.4, 133. ,  96. , ...,   nan,   nan,   nan]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npval[1003:1009,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32eee38-a1bd-459f-9f35-3c0e32323140",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('npval.csv', npval, delimiter=',')\n",
    "file_name = \"npval.csv\"\n",
    "file_key = \"Labrado/alllabs1000adm/npval.csv\"\n",
    "s3.upload_file(file_name, bucket_name,file_key)\n",
    "\n",
    "np.savetxt('nptime.csv', nptime, delimiter=',')\n",
    "file_name = \"nptime.csv\"\n",
    "file_key = \"Labrado/alllabs1000adm/nptime.csv\"\n",
    "s3.upload_file(file_name, bucket_name,file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc776dbb-f1c4-4e06-9779-55b36d679d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('npval_last.csv', npval_last, delimiter=',')\n",
    "file_name = \"npval_last.csv\"\n",
    "file_key = \"Labrado/alllabs1000adm/npval_last.csv\"\n",
    "s3.upload_file(file_name, bucket_name,file_key)\n",
    "\n",
    "np.savetxt('nptime_last.csv', nptime_last, delimiter=',')\n",
    "file_name = \"nptime_last.csv\"\n",
    "file_key = \"Labrado/alllabs1000adm/nptime_last.csv\"\n",
    "s3.upload_file(file_name, bucket_name,file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c142fb50-0ee1-411b-b7a8-b8a08fa90f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Labitemlist.csv', Labitemlist, delimiter=',')\n",
    "file_name = \"Labitemlist.csv\"\n",
    "file_key = \"Labrado/alllabs1000adm/Labitemlist.csv\"\n",
    "s3.upload_file(file_name, bucket_name,file_key)\n",
    "\n",
    "np.savetxt('unique_adm_year_day.csv', unique_adm_year_day, delimiter=',')\n",
    "file_name = \"unique_adm_year_day.csv\"\n",
    "file_key = \"Labrado/alllabs1000adm/unique_adm_year_day.csv\"\n",
    "s3.upload_file(file_name, bucket_name,file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "443c73aa-75f6-4fd4-b18e-3155957b720e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'sagemaker-studio-905418013525-nvxe84zgs6'\n",
    "\n",
    "\n",
    "file_path = 'Labrado/alllabs1000adm/npval.csv'\n",
    "obj = s3.get_object(Bucket=bucket_name, Key=file_path)\n",
    "npval = pd.read_csv(obj['Body'], header=None, dtype=float)\n",
    "\n",
    "\n",
    "file_path = 'Labrado/alllabs1000adm/npval_last.csv'\n",
    "obj = s3.get_object(Bucket=bucket_name, Key=file_path)\n",
    "npval_last = pd.read_csv(obj['Body'], header=None, dtype=float)\n",
    "\n",
    "file_path = 'Labrado/alllabs1000adm/nptime.csv'\n",
    "obj = s3.get_object(Bucket=bucket_name, Key=file_path)\n",
    "nptime = pd.read_csv(obj['Body'], header=None, dtype=float)\n",
    "\n",
    "file_path = 'Labrado/alllabs1000adm/nptime_last.csv'\n",
    "obj = s3.get_object(Bucket=bucket_name, Key=file_path)\n",
    "nptime_last = pd.read_csv(obj['Body'], header=None, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9085b60c-bd9a-446a-aa7d-651bc28f21f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>365</th>\n",
       "      <th>366</th>\n",
       "      <th>367</th>\n",
       "      <th>368</th>\n",
       "      <th>369</th>\n",
       "      <th>370</th>\n",
       "      <th>371</th>\n",
       "      <th>372</th>\n",
       "      <th>373</th>\n",
       "      <th>374</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "      <td>137.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.7</td>\n",
       "      <td>136.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.9</td>\n",
       "      <td>138.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.2</td>\n",
       "      <td>140.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>32.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.8</td>\n",
       "      <td>141.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>30.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 375 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2     3    4     5     6     7      8      9    ...  365  \\\n",
       "0  3.5  137.0  103.0  26.5  1.1  24.0  14.0  19.0  169.0  183.0  ...  NaN   \n",
       "1  3.7  136.0  100.0  28.1  1.2  28.0  12.0  17.0  190.0  195.0  ...  NaN   \n",
       "2  3.9  138.0  102.0  24.4  0.9  26.0  14.0  14.0  177.0  188.0  ...  NaN   \n",
       "3  5.2  140.0  104.0  32.1  1.1  25.0  16.0  28.0   88.0  196.0  ...  NaN   \n",
       "4  4.8  141.0  106.0  30.3  2.3  24.0  11.0  26.0  165.0  157.0  ...  NaN   \n",
       "\n",
       "   366  367  368  369  370  371  372  373  374  \n",
       "0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 375 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3f935f2-f75b-42f5-90a2-839b4f4d53e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split year is 2178\n"
     ]
    }
   ],
   "source": [
    "file_path = 'Labrado/alllabs1000adm/Labitemlist.csv'\n",
    "obj = s3.get_object(Bucket=bucket_name, Key=file_path)\n",
    "Labitemlist = pd.read_csv(obj['Body'], header=None,names=['labitem', 'cnt'], dtype=int)\n",
    "file_path = 'Labrado/alllabs1000adm/unique_adm_year_day.csv'\n",
    "obj = s3.get_object(Bucket=bucket_name, Key=file_path)\n",
    "unique_adm_year_day = pd.read_csv(obj['Body'], header=None,names=['hadm_id', 'chartyear', 'day','rowinx'], dtype=int)\n",
    "unique_hadm_by_year = unique_adm_year_day.groupby('chartyear')['hadm_id'].nunique()\n",
    "cumulative_sum = unique_hadm_by_year.cumsum()\n",
    "total_sum = cumulative_sum.iloc[-1]\n",
    "split_index = cumulative_sum[cumulative_sum >= 0.8 * total_sum].index[0]\n",
    "print(\"split year is\",split_index)\n",
    "Row_Train = unique_adm_year_day['chartyear']<=split_index\n",
    "Train_inx = Row_Train[Row_Train].index\n",
    "Row_Test = unique_adm_year_day['chartyear']>split_index\n",
    "Test_inx = Row_Test[Row_Test].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef7b1df-b4bf-4c5f-962d-5a8b218c0217",
   "metadata": {},
   "outputs": [],
   "source": [
    "LanCnt = 100\n",
    "\n",
    "X_train = np.full((len(Train_inx),LanCnt*4), np.nan)\n",
    "X_train[:,0:LanCnt*2:2] = npval.iloc[Train_inx,:LanCnt]\n",
    "X_train[:,1:LanCnt*2:2] = nptime.iloc[Train_inx,:LanCnt]\n",
    "X_train[:,LanCnt*2:LanCnt*4:2] = npval_last.iloc[Train_inx,:LanCnt]\n",
    "X_train[:,LanCnt*2+1:LanCnt*4:2] = nptime_last.iloc[Train_inx,:LanCnt]\n",
    "\n",
    "X_test = np.full((len(Test_inx),LanCnt*4), np.nan)\n",
    "X_test[:,0:LanCnt*2:2] = npval.iloc[Test_inx,:LanCnt]\n",
    "X_test[:,1:LanCnt*2:2] = nptime.iloc[Test_inx,:LanCnt]\n",
    "X_test[:,LanCnt*2:LanCnt*4:2] = npval_last.iloc[Test_inx,:LanCnt]\n",
    "X_test[:,LanCnt*2+1:LanCnt*4:2] = nptime_last.iloc[Test_inx,:LanCnt]\n",
    "\n",
    "X_train_df = pd.DataFrame(X_train)\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "\n",
    "# Optionally, you can assign column names to the DataFrames\n",
    "# Generate column names for each part of the DataFrame\n",
    "col_names = []\n",
    "for i in range(LanCnt):\n",
    "    col_names.append(f'npval_{Labitemlist[i,0]}')\n",
    "    col_names.append(f'nptime_{Labitemlist[i,0]}')\n",
    "for i in range(LanCnt):\n",
    "    col_names.append(f'npval_last_{Labitemlist[i,0]}')\n",
    "    col_names.append(f'nptime_last_{Labitemlist[i,0]}')\n",
    "\n",
    "X_train_df.to_csv('X_train.csv', index=False)\n",
    "\n",
    "\n",
    "file_name = \"X_train.csv\"\n",
    "file_key = \"Labrado/alllabs1000adm/X_train.csv\"\n",
    "s3.upload_file(file_name, bucket_name,file_key)\n",
    "\n",
    "X_test_df.to_csv('X_test.csv', index=False)\n",
    "file_name = \"X_test.csv\"\n",
    "file_key = \"Labrado/alllabs1000adm/X_test.csv\"\n",
    "s3.upload_file(file_name, bucket_name,file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3f68f0-5763-4f7b-9b58-ca416db15c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "ItemID = 2\n",
    "columns_to_remove = [ItemID*2, ItemID*2+1]  # Assuming you want to remove the second and third columns (0-indexed)\n",
    "\n",
    "y_train = X_train[:,ItemID*2]\n",
    "X_train = X_train[~np.isnan(y_train),:]\n",
    "y_train = y_train[~np.isnan(y_train)]\n",
    "\n",
    "y_test = X_test[:,ItemID*2]\n",
    "X_test = X_test[~np.isnan(y_test),:]\n",
    "y_test = y_test[~np.isnan(y_test)]\n",
    "\n",
    "X_train = np.delete(X_train, columns_to_remove, axis=1)\n",
    "X_test = np.delete(X_test, columns_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "af329e64-6ddc-46cd-b855-58b295141e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost_model(X_train, X_test, y_train, y_test):\n",
    "    # Split the data into training and testing sets\n",
    "\n",
    "    # Define the XGBoost model\n",
    "    model = xgb.XGBRegressor(objective=\"reg:squarederror\")\n",
    "\n",
    "    # Define the hyperparameter grid for grid search\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'n_estimators': [50, 100, 200],\n",
    "    }\n",
    "\n",
    "    # Use GridSearchCV to find the best hyperparameters\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=3)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best model from the grid search\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Make predictions on the test set using the best model\n",
    "    predictions = best_model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    std_dev = np.std(y_test - predictions)  # Standard deviation of residuals\n",
    "\n",
    "    return {\n",
    "        \"y_test\": y_test,\n",
    "        \"predictions\": predictions,\n",
    "        \"mse\": mse,\n",
    "        \"mae\": mae,\n",
    "        \"r2\": r2,\n",
    "        \"std_dev\": std_dev,\n",
    "        \"best_params\": grid_search.best_params_\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1b5151-4fed-4866-b979-b40dd40074ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time: 2024-05-20 22:12:11.431524\n",
      "Current time: 2024-05-21 00:01:54.058934\n",
      "{'y_test': array([102., 103., 103., ..., 110., 101., 100.]), 'predictions': array([101.974, 103.122, 103.336, ..., 110.294, 101.126,  99.847],\n",
      "      dtype=float32), 'mse': 0.7537429154574968, 'mae': 0.5347291202779194, 'r2': 0.9754317327054305, 'std_dev': 0.86813829526865, 'best_params': {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 200}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Current time:\", datetime.now())\n",
    "model_results = train_xgboost_model(X_train, X_test, y_train, y_test)\n",
    "print(\"Current time:\", datetime.now())\n",
    "print(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54674a76-baa5-4317-be4e-e56519168774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def mse_r2_confusion_matrix(ground_truth, predictions, normal_range):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Squared Error (MSE), R-squared value (R2), and confusion matrix for two arrays, ignoring NaN values.\n",
    "    The confusion matrix will be based on three categories: lower, normal, and higher.\n",
    "\n",
    "    Parameters:\n",
    "    ground_truth (numpy.ndarray): Ground truth array.\n",
    "    predictions (numpy.ndarray): Predicted values array.\n",
    "    normal_range (tuple): Normal range as a tuple (min, max).\n",
    "\n",
    "    Returns:\n",
    "    tuple: Three elements:\n",
    "        - float: MSE value.\n",
    "        - float: R-squared value.\n",
    "        - numpy.ndarray: Confusion matrix.\n",
    "    \"\"\"\n",
    "    # Ensure input arrays are numpy arrays\n",
    "    ground_truth = np.asarray(ground_truth)\n",
    "    predictions = np.asarray(predictions)\n",
    "\n",
    "    if ground_truth.shape != predictions.shape:\n",
    "        raise ValueError(\"The shapes of the ground truth and prediction arrays must be the same.\")\n",
    "\n",
    "    # Handle NaN values by masking\n",
    "    mask = np.isnan(ground_truth) | np.isnan(predictions)\n",
    "    gt = ground_truth[~mask]\n",
    "    pred = predictions[~mask]\n",
    "\n",
    "    # Calculate MSE\n",
    "    mse = np.mean((gt - pred) ** 2)\n",
    "\n",
    "    # Calculate R-squared\n",
    "    mean_gt = np.mean(gt)\n",
    "    tss = np.sum((gt - mean_gt) ** 2)\n",
    "    rss = np.sum((gt - pred) ** 2)\n",
    "    r2 = 1 - rss / tss\n",
    "\n",
    "    # Normal range handling\n",
    "    normal_min, normal_max = normal_range\n",
    "    gt_category = np.where(gt < normal_min, 0, np.where(gt > normal_max, 2, 1))\n",
    "    pred_category = np.where(pred < normal_min, 0, np.where(pred > normal_max, 2, 1))\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(gt_category, pred_category, labels=[0, 1, 2])\n",
    "\n",
    "    return mse, r2, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cc9617-988f-40da-a613-514b71e661d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 106)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_ranges[ItemID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e475508-c290-4ed3-91d1-78e082f7ea16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(331789, 398)\n",
      "(98, 106)\n",
      "Overall Xgboost MSE: 0.754\n",
      "Overall Xgboost R-squared: 0.975\n",
      "Overall Xgboost Confusion matrix:\n",
      " [[ 59695   1875      8]\n",
      " [  8587 188238  10357]\n",
      " [     8   1958  61063]]\n",
      "Test with the last value 262513\n",
      "last value prediction MSE per column: 8.909\n",
      "last value prediction R-squared per column: 0.719\n",
      "last value prediction Confusion matrix:\n",
      " [[ 39122  12455    155]\n",
      " [ 12917 131962  16472]\n",
      " [   188  14743  34499]]\n",
      "XGBoost for those with last value MSE : 0.626\n",
      "XGBoost for those with last value R-squared: 0.98\n",
      "XGBoost for those with last value Confusion matrix:\n",
      " [[ 50619   1109      4]\n",
      " [  6810 146416   8125]\n",
      " [     6   1326  48098]]\n"
     ]
    }
   ],
   "source": [
    "normal_ranges = [(3.5,5),(136,145),(98,106),(37,50),(0.7,1.3),(23,28),(7,13),(8,20),(0,200),(150,450)]\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "print(X_test.shape)\n",
    "print(normal_ranges[ItemID])\n",
    "\n",
    "\n",
    "y_pred = model_results['predictions']\n",
    "mse, r2, cm = mse_r2_confusion_matrix(y_test, y_pred, normal_ranges[ItemID])\n",
    "\n",
    "print(\"Overall Xgboost MSE:\", round(mse,3))\n",
    "print(\"Overall Xgboost R-squared:\", round(r2,3))\n",
    "print(\"Overall Xgboost Confusion matrix:\\n\", cm)\n",
    "\n",
    "y_last = X_test[:,ItemID*2+LanCnt*2-2]\n",
    "valid_pos = ~np.isnan(y_last)\n",
    "print('Test with the last value',len(y_last[valid_pos]))\n",
    "mse, r2, cm = mse_r2_confusion_matrix(y_test, y_last, normal_ranges[ItemID])\n",
    "print(\"last value prediction MSE per column:\", round(mse,3))\n",
    "print(\"last value prediction R-squared per column:\", round(r2,3))\n",
    "print(\"last value prediction Confusion matrix:\\n\", cm)\n",
    "\n",
    "\n",
    "valid_pos = ~np.isnan(y_last)\n",
    "mse, r2, cm = mse_r2_confusion_matrix(y_test[valid_pos], y_pred[valid_pos], normal_ranges[ItemID])\n",
    "print(\"XGBoost for those with last value MSE :\", round(mse,3))\n",
    "print(\"XGBoost for those with last value R-squared:\", round(r2,3))\n",
    "print(\"XGBoost for those with last value Confusion matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267ce20e-a95b-4687-92f9-a31f2134cb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
